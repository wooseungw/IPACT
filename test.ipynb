{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize variables\n",
    "documents = []\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the PDF files\n",
    "pdf_directory = './data'\n",
    "\n",
    "# Use glob to get all PDF files in the directory\n",
    "pdf_files = glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "# Load all PDF files using PyPDFLoader\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pdf_documents = loader.load()\n",
    "    documents.extend(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks\n",
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = chunk_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-4o\", temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chatbot response function\n",
    "def get_chatbot_response(chatbot_response):\n",
    "    print(chatbot_response['result'].strip())\n",
    "    print('\\n문서 출처:')\n",
    "    for source in chatbot_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가족과의 대화 시간이 부족하다고 느낀다.\n",
      "가족과 함께 있는 시간이 충분하지 않다고 생각한다.\n",
      "\n",
      "언제 외로움을 느끼셨나요? 예시를 들어주세요.\n",
      "외롭다는 사실을 알게되신 상황이 어떤건가요?\n",
      "가족과 있을때 필요한것이 무엇이었나요?\n",
      "가장 외로웠던 상황은 가족들과 떨어져 살았을때 입니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('data/kgls_dummy.json') as file:\n",
    "    kgls = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "print(kgls['Family'][0]['question'])\n",
    "print(kgls['Family'][1]['question'])\n",
    "print()\n",
    "with open('data/qa.json') as file:\n",
    "    q = json.load(file)\n",
    "print(q['Q'][0]['Qusetion'])\n",
    "print(q['Q'][1]['Qusetion'])\n",
    "print(q['Q'][2]['Qusetion'])\n",
    "print(q['A'][0]['Answer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_class import GPT\n",
    "\n",
    "load_dotenv()\n",
    "openai = os.getenv(\"OPENAI_API_KEY\")\n",
    "## Example\n",
    "gpt = GPT(api_key=openai, model=\"gpt-4o\", sys_prompt=\"너는 외로움을 분석하는 모델이야 사용자의 kgls결과를 바탕으로 사용자의 외로움을 분석하고 답변해줄 수 있어.\")\n",
    "img_prompt =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#임베딩\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#OpenAi와 Chormadb사용\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m(api_key\u001b[38;5;241m=\u001b[39mOPENAI_API_KEY)\n\u001b[1;32m     24\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(documents\u001b[38;5;241m=\u001b[39mchunks, embedding\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[1;32m     25\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "dir = './data'\n",
    "\n",
    "pdf_files = glob(os.path.join(dir, '*.pdf'))\n",
    "\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pdf_documents = loader.load()\n",
    "    documents.extend(pdf_documents)\n",
    "\n",
    "#청크로 나누고 문서를 저장\n",
    "# RecursiveCharacterTextSplitter를 사용하여 문서를 청크로 나누기\n",
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = chunk_splitter.split_documents(documents)\n",
    "\n",
    "#임베딩\n",
    "#OpenAi와 Chormadb사용\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "#QA체인 만들기\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-4\", temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyserverprog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
