{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Initialize variables\n",
    "documents = []\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the directory containing the PDF files\n",
    "pdf_directory = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문을 벡터 db에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf를 사용해서 pdf(논문)을 모두 로드\n",
    "pdf_files = glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "# Load all PDF files using PyPDFLoader\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pdf_documents = loader.load()\n",
    "    documents.extend(pdf_documents)\n",
    "    \n",
    "# 텍스트는 RecursiveCharacterTextSplitter를 사용하여 분할\n",
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = chunk_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings은 OpenAI의 임베딩을 사용\n",
    "# vectordb는 chromadb사용함\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인적정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김영수\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class User:\n",
    "    def __init__(self, info_dir):\n",
    "        # Read the JSON file\n",
    "        with open(info_dir, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        self.name = data['name']\n",
    "        self.phone = data['phone']\n",
    "        self.age = data['age']\n",
    "        self.gender = data['gender']\n",
    "        self.education = data['education']\n",
    "        self.merry = data['merry']\n",
    "        self.children = data['children']\n",
    "        self.religion = data['religion']\n",
    "        self.income = data['income']\n",
    "        self.economy_states = data['economy_states']\n",
    "        self.health_states = data['health_states']\n",
    "        \n",
    "# Specify the path to the JSON file\n",
    "info_dir = 'data/user_info.json'\n",
    "user = User(info_dir)\n",
    "print(user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = f\"\"\"\n",
    "    사용자의 인적정보, KGLS 질문과 사용자의 답변 , 사용자가 입력한 주관식 답변 그리고 노인들의 외로움과 한국형 외로움에 대한 연구를 바탕으로 어떤 한국형 외로움을 가지고있는지 설명해주세요. \\\\\n",
    "    그 사용자에게 적절한 대화 상대가 되어주기 위한 프롬프트를 출력해주세요. \\\\\n",
    "    사용자의 이름은 {user.name}, 나이는 {user.age}, 성별은 {user.gender}, 학력은 {user.education}, 결혼 여부는 {user.merry}, 자녀 수는 {user.children}, 종교는 {user.religion}, 소득은 {user.income}, 경제 상태는 {user.economy_states}, 건강 상태는 {user.health_states}입니다. \\\\\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "INPUT_PROMPT = f\"\"\"\n",
    "라고 대답했습니다. \\\\\n",
    "이 사용자가 가지고 있는 한국형 외로움을 설명해주세요. \\\\\n",
    "그리고 어떤 대화 상대가 되어주어야 하는지 출력해주세요\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> 김영수님, 안녕하세요. 요즘 어떻게 지내고 계신가요? 최근에 어떤 일들이 있었는지, 그리고 그 일들에 대해 어떤 생각을 하고 계신지 궁금합니다. 가족들과의 대화나 일상에서 느끼는 감정들에 대해 이야기해주시면 좋겠어요. 특히, 가족들과의 대화에서 어떤 점이 아쉬운지, 그리고 어떤 대화를 나누고 싶은지 말씀해주시면 좋겠습니다. 저는 김영수님의 이야기를 듣고 공감하며, 함께 고민을 나누고 싶습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 및 모듈을 임포트합니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿을 정의합니다.\n",
    "# SYS_PROMPT는 시스템 메시지로, 템플릿에 포함됩니다. \n",
    "# {context}와 {question}은 실행 시 동적으로 채워질 자리표시자입니다.\n",
    "template = SYS_PROMPT + '''Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "# ChatPromptTemplate.from_template() 메서드를 사용하여 프롬프트 템플릿을 생성합니다.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 인스턴스를 생성하여 LLM (대규모 언어 모델)을 설정합니다.\n",
    "# 여기서는 'gpt-4o' 모델을 사용하고, temperature는 0으로 설정하여 출력의 일관성을 높입니다.\n",
    "model = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# 문서들을 형식화하는 함수를 정의합니다.\n",
    "# 각 문서의 페이지 내용을 합쳐 하나의 문자열로 반환합니다.\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG (Retrieval-Augmented Generation) 체인을 연결합니다.\n",
    "# 이 체인은 문서 검색, 형식화, 프롬프트 적용, 모델 호출, 출력 파싱의 과정을 거칩니다.\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}  # 'context'는 retriever와 format_docs를 통해 설정되고, 'question'은 그대로 전달됩니다.\n",
    "    | prompt  # 프롬프트 템플릿을 적용합니다.\n",
    "    | model  # 모델을 호출합니다.\n",
    "    | StrOutputParser()  # 출력 파서를 통해 모델의 출력을 문자열로 변환합니다.\n",
    ")\n",
    "\n",
    "# 체인을 실행합니다.\n",
    "# 입력 메시지는 질문과 답변 형식의 텍스트입니다.\n",
    "input_message =  \"\"\"\n",
    "Q: 어떤 상황에서 외로움을 느끼시나요? \\\\\n",
    "A: 가장 외로웠던 상황은 가족들과 떨어져 살았을 때입니다. 내가 젊을 때 기러기 아빠였어요. 밤에 혼자 집에 가는데 집에 가도 아무도 없겠구나 싶어서 힘들더라고요. 지금도 가끔 생각나요. \\\\\n",
    "\"\"\" + INPUT_PROMPT  # 추가적인 입력 프롬프트가 이어집니다.\n",
    "\n",
    "# to_markdown() 함수를 호출하여 체인의 결과를 마크다운 형식으로 변환합니다.\n",
    "to_markdown(rag_chain.invoke(\"input_message\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiservice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
