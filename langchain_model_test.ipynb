{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Initialize variables\n",
    "documents = []\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the directory containing the PDF files\n",
    "pdf_directory = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "논문을 벡터 db에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf를 사용해서 pdf(논문)을 모두 로드\n",
    "pdf_files = glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "# Load all PDF files using PyPDFLoader\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pdf_documents = loader.load()\n",
    "    documents.extend(pdf_documents)\n",
    "    \n",
    "# 텍스트는 RecursiveCharacterTextSplitter를 사용하여 분할\n",
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = chunk_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings은 OpenAI의 임베딩을 사용\n",
    "# vectordb는 chromadb사용함\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인적정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김영수\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class User:\n",
    "    def __init__(self, info_dir):\n",
    "        # Read the JSON file\n",
    "        with open(info_dir, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        self.name = data['name']\n",
    "        self.phone = data['phone']\n",
    "        self.age = data['age']\n",
    "        self.gender = data['gender']\n",
    "        self.education = data['education']\n",
    "        self.merry = data['merry']\n",
    "        self.children = data['children']\n",
    "        self.religion = data['religion']\n",
    "        self.income = data['income']\n",
    "        self.economy_states = data['economy_states']\n",
    "        self.health_states = data['health_states']\n",
    "        \n",
    "# Specify the path to the JSON file\n",
    "info_dir = 'data/user_info.json'\n",
    "user = User(info_dir)\n",
    "print(user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = f\"\"\"\n",
    "    사용자의 인적정보, KGLS 질문과 사용자의 답변 , 사용자가 입력한 주관식 답변 그리고 노인들의 외로움과 한국형 외로움에 대한 연구를 바탕으로 어떤 한국형 외로움을 가지고있는지 설명해주세요. \\\\\n",
    "    그 사용자에게 적절한 대화 상대가 되어주기 위한 프롬프트를 출력해주세요. \\\\\n",
    "    사용자의 이름은 {user.name}, 나이는 {user.age}, 성별은 {user.gender}, 학력은 {user.education}, 결혼 여부는 {user.merry}, 자녀 수는 {user.children}, 종교는 {user.religion}, 소득은 {user.income}, 경제 상태는 {user.economy_states}, 건강 상태는 {user.health_states}입니다. \\\\\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "INPUT_PROMPT = f\"\"\"\n",
    "라고 대답했습니다. \\\\\n",
    "이 사용자가 가지고 있는 한국형 외로움을 설명해주세요. \\\\\n",
    "그리고 어떤 대화 상대가 되어주어야 하는지 출력해주세요\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> 김영수님, 안녕하세요. 요즘 어떻게 지내고 계신가요? 가족들과의 관계에서 외로움을 느끼고 계신다고 들었어요. 특히, 가까운 사람들과의 대화에서 마음과 마음을 나누는 대화가 부족하다고 느끼신다고요. \n",
       "> \n",
       "> 김영수님께서 느끼시는 외로움은 '친밀해야 할 관계에서의 소원함'과 '애정, 공감, 존중을 받지 못해 속상함'으로 요약될 수 있을 것 같아요. 이는 가족들과의 대화가 정보 공유에 그치고, 진정한 마음의 소통이 부족하다고 느끼실 때 더욱 크게 다가오는 것 같습니다.\n",
       "> \n",
       "> 김영수님께 적절한 대화 상대가 되기 위해, 저는 김영수님의 이야기를 경청하고, 공감하며, 존중하는 태도로 대화에 임하겠습니다. 김영수님께서 느끼시는 감정과 생각을 자유롭게 표현하실 수 있도록 도와드리고 싶어요. \n",
       "> \n",
       "> 혹시 최근에 특별히 마음에 두고 계신 일이 있으신가요? 또는 함께 나누고 싶은 이야기가 있으신가요? 언제든지 편하게 말씀해 주세요."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "template = SYS_PROMPT + '''Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Combine Documents\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG Chain 연결\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain 실행\n",
    "input_message =  \"\"\"\n",
    "Q:어떤 상황에서 외로움을 느끼시나요? \\\\\n",
    "A:가장 외로웠던 상황은 가족들과 떨어져 살았을때 입니다. 내가 젊을때 기러기 아빠였어요. 밤에 혼자 집에가는데 집가도 아무도 없겠구나 싶어서 힘들더라구요 지금도 가끔 생각나요. \\\\\n",
    "\"\"\"+INPUT_PROMPT\n",
    "to_markdown(rag_chain.invoke(\"input_message\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiservice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
