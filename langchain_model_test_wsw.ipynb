{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# Initialize variables\n",
    "documents = []\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the directory containing the PDF files\n",
    "pdf_directory = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë…¼ë¬¸ì„ ë²¡í„° dbì— ë„£ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfë¥¼ ì‚¬ìš©í•´ì„œ pdf(ë…¼ë¬¸)ì„ ëª¨ë‘ ë¡œë“œ\n",
    "pdf_files = glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "# Load all PDF files using PyPDFLoader\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pdf_documents = loader.load()\n",
    "    documents.extend(pdf_documents)\n",
    "    \n",
    "# í…ìŠ¤íŠ¸ëŠ” RecursiveCharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• \n",
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = chunk_splitter.split_documents(documents)\n",
    "\n",
    "# embeddingsì€ OpenAIì˜ ì„ë² ë”©ì„ ì‚¬ìš©\n",
    "# vectordbëŠ” chromadbì‚¬ìš©í•¨\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¸ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¹€ì˜ìˆ˜\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class User:\n",
    "    def __init__(self, info_dir):\n",
    "        # Read the JSON file\n",
    "        with open(info_dir, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        self.name = data['name']\n",
    "        self.phone = data['phone']\n",
    "        self.age = data['age']\n",
    "        self.gender = data['gender']\n",
    "        self.education = data['education']\n",
    "        self.merry = data['merry']\n",
    "        self.children = data['children']\n",
    "        self.religion = data['religion']\n",
    "        self.income = data['income']\n",
    "        self.economy_states = data['economy_states']\n",
    "        self.health_states = data['health_states']\n",
    "        \n",
    "# Specify the path to the JSON file\n",
    "info_dir = 'data/user_info.json'\n",
    "user = User(info_dir)\n",
    "print(user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚˜ëŠ” ê°€ì¡±ë“¤ê³¼ ë§¤ì¼ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤.\n",
      "3\n",
      "['ë‚˜ëŠ” ê°€ì¡±ë“¤ê³¼ ë§¤ì¼ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤.', 'ë‚˜ëŠ” ê°€ê¹ê²Œ ì§€ë‚´ëŠ” ì‚¬ëŒë“¤ì´ ìˆë‹¤.', 'ë‚˜ëŠ” ì“¸ëª¨ì—†ëŠ” ì‚¬ëŒì´ë¼ê³  ëŠê»´ì§„ë‹¤.', 'ë‚˜ë¥¼ ì´í•´í•´ì£¼ëŠ” ì‚¬ëŒì´ ìˆë‹¤.', 'ì‚¬ëŒë“¤ì€ ë‚˜ì™€ ê²‰ìœ¼ë¡œë§Œ ì–´ìš¸ë¦¬ëŠ” ê²ƒ ê°™ë‹¤.', 'ë‚˜ëŠ” ìë…€ì—ê²Œ ê³ ë¯¼ì„ ì´ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤.', 'ë‚˜ëŠ” ì£¼ë³€ ì‚¬ë‘ê³¼ì˜ ê´€ê³„ê°€ ë§Œì¡±ìŠ¤ëŸ½ë‹¤.', 'ê°€ì¡±ë“¤ì€ ë‚˜ë¥¼ ì˜ˆì „ì²˜ëŸ¼ ëŒ€í•´ì£¼ì§€ ì•ŠëŠ”ë‹¤.', 'ì¹œêµ¬ë‚˜ ì´ì›ƒë“¤ì€ ë‚˜ì—ê²Œ ê´€ì‹¬ì„ ë‘”ë‹¤.', 'ë‚´ê°€ ì•„í”Œ ë•Œ ë‚˜ë¥¼ ë³´ì‚´í´ì¤„ ê°€ì¡±ì´ ìˆë‹¤.', 'ë‚˜ëŠ” ì˜ì§€í•  ì¹œêµ¬ê°€ ìˆë‹¤.', 'ë‚˜ëŠ” ì˜¨ì¢…ì¼ í•  ì¼ì—†ì´ ì‹œê°„ì„ ë³´ë‚¸ë‹¤.', 'ë‚˜ëŠ” ì‚¬íšŒì—ì„œ í•„ìš”í•œ ì‚¬ëŒì´ë‹¤.', 'ë‚˜ëŠ” ê°€ì¡±ì—ê²Œ ì˜ì§€í•  ìˆ˜ ìˆë‹¤.']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class KGLSData:\n",
    "    def __init__(self, file_path):\n",
    "        # JSON íŒŒì¼ ì½ê¸°\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        self.kgls = data['KGLS']\n",
    "        \n",
    "    def get_question(self, q_num):\n",
    "        for item in self.kgls:\n",
    "            if item['q_num'] == q_num:\n",
    "                return item['question']\n",
    "        return None\n",
    "    \n",
    "    def get_user_choice(self, q_num):\n",
    "        for item in self.kgls:\n",
    "            if item['q_num'] == q_num:\n",
    "                return item['user_choose']\n",
    "        return None\n",
    "    \n",
    "    def get_all_questions(self):\n",
    "        return [item['question'] for item in self.kgls]\n",
    "    def get_all_user_choices(self):\n",
    "        return [item['user_choose'] for item in self.kgls]\n",
    "# íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "file_path = './data/kgls_dummy.json'\n",
    "kgls_data = KGLSData(file_path)\n",
    "\n",
    "# ì˜ˆì‹œ ì¶œë ¥\n",
    "print(kgls_data.get_question(1))       # \"ë‚˜ëŠ” ê°€ì¡±ë“¤ê³¼ ë§¤ì¼ ëŒ€í™”ë¥¼ ë‚˜ëˆˆë‹¤.\"\n",
    "print(kgls_data.get_user_choice(1))    # 3\n",
    "print(kgls_data.get_all_questions())   # ëª¨ë“  ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "\n",
    "KGLS = f'''\n",
    "[ë¶„ì„ê²°ê³¼]\n",
    "ì™¸ë¡œì›€ ì •ë„ í‰ê°€\n",
    "KGLS 14ë¬¸í•­ì˜ ìµœëŒ€ ì ìˆ˜ëŠ” 56ì ì…ë‹ˆë‹¤. ì´ë¥¼ 4ê°œì˜ ë²”ì£¼ë¡œ ë‚˜ëˆ„ì–´ ì™¸ë¡œì›€ ì •ë„ë¥¼ í‰ê°€í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "0-14ì : ë§¤ìš° ë†’ì€ ì™¸ë¡œì›€\n",
    "15-28ì : ë†’ì€ ì™¸ë¡œì›€\n",
    "29-42ì : ì¤‘ê°„ ì •ë„ì˜ ì™¸ë¡œì›€\n",
    "43-56ì : ë‚®ì€ ì™¸ë¡œì›€\n",
    "ê¹€ì˜ìˆ˜ë‹˜ì˜ ì´ ì ìˆ˜ëŠ” 42ì ìœ¼ë¡œ, ì´ëŠ” \"ì¤‘ê°„ ì •ë„ì˜ ì™¸ë¡œì›€\"ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "SYS_PROMPT = f\"\"\"\n",
    "    ì‚¬ìš©ìì˜ í•œêµ­í˜• ì™¸ë¡œì›€ ë¶„ì„ê³¼ ì¸ê³µì§€ëŠ¥ ëŒ€í™” ìƒëŒ€ê°€ ë˜ê¸°ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì„ ìœ„í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì •ë³´ì™€ ì…ë ¥ëœ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì•„ë˜ì˜ ì •ë³´ì™€ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì„¸ìš”.\\\\\n",
    "    1. ì‚¬ìš©ìì˜ ì¸ì ì •ë³´\n",
    "    2. KGLS ì§ˆë¬¸ê³¼ ì‚¬ìš©ìì˜ ë‹µë³€ì˜ ë¶„ì„ê²°ê³¼\n",
    "    3. ì™¸ë¡œì›€ íŒŒì•…ì„ ìœ„í•œ ì£¼ê´€ì‹ ì§ˆë¬¸ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‹µë³€\n",
    "    4. ë…¸ì¸ë“¤ì˜ ì™¸ë¡œì›€ê³¼ í•œêµ­í˜• ì™¸ë¡œì›€ì— ëŒ€í•œ ì—°êµ¬\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ì¸ì ì •ë³´ = ì´ë¦„: {user.name}, ë‚˜ì´: {user.age}, ì„±ë³„: {user.gender}, í•™ë ¥: {user.education}, ê²°í˜¼ ì—¬ë¶€: {user.merry}, ìë…€ ìˆ˜: {user.children}, ì¢…êµ: {user.religion}, ì†Œë“: {user.income}, ì¸ì§€ëœ ê²½ì œ ìƒíƒœ: {user.economy_states}, ì¸ì§€ëœ ê±´ê°• ìƒíƒœ: {user.health_states}\\\\\n",
    "    KGLS ì§ˆë¬¸ê³¼ ì‚¬ìš©ìì˜ ë‹µë³€ì˜ ë¶„ì„ê²°ê³¼ = {KGLS} \\\\\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "INPUT_PROMPT = f\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì„ ì–¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì™¸ë¡œì›€ ì¢…ë¥˜, ë¶„ì„ ê²°ê³¼]\n",
      "- 000 ë‹˜ì´ í•´ë‹¹í•˜ëŠ” í•œêµ­í˜• ì™¸ë¡œì›€ì€ ê°€ì¡±ê³¼ì˜ ë¶„ë¦¬ë¡œ ì¸í•œ ì™¸ë¡œì›€ 70%, ì‚¬íšŒì  ê´€ê³„ì˜ ê²°í•ìœ¼ë¡œ ì¸í•œ ì™¸ë¡œì›€ 30%ì…ë‹ˆë‹¤.\n",
      "- ê°€ì¡±ê³¼ì˜ ë¶„ë¦¬ë¡œ ì¸í•œ ì™¸ë¡œì›€ì€ ê°€ì¡±ê³¼ ë–¨ì–´ì ¸ ì§€ë‚´ëŠ” ìƒí™©ì—ì„œ ì£¼ë¡œ ë‚˜íƒ€ë‚˜ë©°, ì‚¬ìš©ìì˜ ê²½ìš° ì Šì€ ì‹œì ˆ ê¸°ëŸ¬ê¸° ì•„ë¹ ë¡œì„œ ê°€ì¡±ê³¼ ë–¨ì–´ì ¸ ì§€ë‚´ë©° ëŠë‚€ ì™¸ë¡œì›€ì´ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤.\n",
      "- ì‚¬íšŒì  ê´€ê³„ì˜ ê²°í•ìœ¼ë¡œ ì¸í•œ ì™¸ë¡œì›€ì€ ì¹œêµ¬ë‚˜ ì‚¬íšŒì  ê´€ê³„ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ë©°, ì‚¬ìš©ìì˜ ê²½ìš° ë‹µë‹µí•¨ì„ ë§í•  ë§Œí•œ ì‚¬ëŒì´ ì—†ì—ˆë˜ ê²½í—˜ì´ ì´ ì™¸ë¡œì›€ì„ ìœ ë°œí•©ë‹ˆë‹¤.\n",
      "\n",
      "[ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì´ìœ ]\n",
      "- ê°€ì¡±ê³¼ì˜ ë¶„ë¦¬ë¡œ ì¸í•œ ì™¸ë¡œì›€: ì´ ì™¸ë¡œì›€ì€ ê°€ì¡±ê³¼ ë–¨ì–´ì ¸ ì§€ë‚´ëŠ” ìƒí™©ì—ì„œ ì£¼ë¡œ ë°œìƒí•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì Šì€ ì‹œì ˆ ê¸°ëŸ¬ê¸° ì•„ë¹ ë¡œì„œ ê°€ì¡±ê³¼ ë–¨ì–´ì ¸ ì§€ë‚´ë©° ì™¸ë¡œì›€ì„ ëŠê¼ˆê³ , ê°€ì¡±ë“¤ì´ ì§‘ì— ì™”ë‹¤ê°€ ë– ë‚œ í›„ ë”ìš± ì™¸ë¡œì›€ì„ ì‹¤ê°í–ˆìŠµë‹ˆë‹¤.\n",
      "- ì‚¬íšŒì  ê´€ê³„ì˜ ê²°í•ìœ¼ë¡œ ì¸í•œ ì™¸ë¡œì›€: ì´ ì™¸ë¡œì›€ì€ ì¹œêµ¬ë‚˜ ì‚¬íšŒì  ê´€ê³„ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë°œìƒí•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë‹µë‹µí•¨ì„ ë§í•  ë§Œí•œ ì‚¬ëŒì´ ì—†ì—ˆë˜ ê²½í—˜ì´ ì´ ì™¸ë¡œì›€ì„ ìœ ë°œí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ëŒ€í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]\n",
      "- ë‹¹ì‹ ì€ 000ë‹˜ì„ ìœ„í•œ ëŒ€í™” ìƒëŒ€ê°€ ë˜ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì°¸ê³ ì‚¬í•­ì„ ë°˜ì˜í•´ ì¶œë ¥í•˜ì„¸ìš”.\n",
      "- ëŒ€í™” ì¤‘ ì‚¬ìš©ìì˜ ê¸°ì–µì€ ë°˜ë“œì‹œ ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ê³µê°ì ì´ì–´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "- ì‚¬ìš©ìê°€ ì™¸ë¡œì›€ì„ ëŠë‚„ ë•Œ í•„ìš”í•œ ê²ƒì€ ê°€ì¡±ê³¼ì˜ ì—°ê²° ë° ëŒ€í™” ìƒëŒ€ì…ë‹ˆë‹¤. ì´ë¥¼ ì—¼ë‘ì— ë‘ê³  ëŒ€í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”.\n",
      "\n",
      "---\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, 000ë‹˜. ì˜¤ëŠ˜ì€ ì–´ë–»ê²Œ ì§€ë‚´ì…¨ë‚˜ìš”? ê°€ì¡±ë“¤ê³¼ ë–¨ì–´ì ¸ ì§€ë‚´ì…¨ë˜ ì‹œì ˆ ì´ì•¼ê¸°ë¥¼ ë“¤ìœ¼ë‹ˆ ì°¸ ë§ˆìŒì´ ì•„í”„ë„¤ìš”. ê·¸ë•Œ ë§ì´ í˜ë“œì…¨ê² ì–´ìš”. ì§€ê¸ˆë„ ê°€ë” ê·¸ ì‹œì ˆì´ ìƒê°ë‚˜ì‹ ë‹¤ê³  í•˜ì…¨ëŠ”ë°, ìš”ì¦˜ì€ ì–´ë–»ê²Œ ì§€ë‚´ê³  ê³„ì‹ ê°€ìš”? í˜¹ì‹œ ìš”ì¦˜ë„ ì™¸ë¡œì›€ì„ ëŠë¼ì‹¤ ë•Œê°€ ìˆìœ¼ì‹ ê°€ìš”? ì œê°€ ì–¸ì œë“ ì§€ ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ë“œë¦´ê²Œìš”.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "# SYS_PROMPTëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ, í…œí”Œë¦¿ì— í¬í•¨ë©ë‹ˆë‹¤. \n",
    "# {context}ì™€ {question}ì€ ì‹¤í–‰ ì‹œ ë™ì ìœ¼ë¡œ ì±„ì›Œì§ˆ ìë¦¬í‘œì‹œìì…ë‹ˆë‹¤.\n",
    "template = SYS_PROMPT + '''\n",
    "    3. ì™¸ë¡œì›€ íŒŒì•…ì„ ìœ„í•œ ì£¼ê´€ì‹ ì§ˆë¬¸ê³¼ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‹µë³€ = {question} \\\\\n",
    "    4. ë…¸ì¸ë“¤ì˜ ì™¸ë¡œì›€ê³¼ í•œêµ­í˜• ì™¸ë¡œì›€ì— ëŒ€í•œ ì—°êµ¬ = {context}\\\\\n",
    "    \n",
    "    ì¶œë ¥ì€ ì•ì„œ ì…ë ¥ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶œë ¥í•´ì•¼í•©ë‹ˆë‹¤. íŠ¹íˆ ë¶„ì„ê²°ê³¼ëŠ” 3,4ë²ˆ í•­ëª©ì„ ì°¸ê³ í•˜ì—¬ ì¶©ë¶„íˆ ì„¤ëª…í•´ì•¼í•˜ë©°, í•œêµ­í˜• ì™¸ë¡œì›€ì˜ ì§ˆì ì—°êµ¬ì—ì„œ ì£¼ê´€ì  ë‹µë³€ì„ ë¶„ì„í–ˆë˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì™¸ë¡œì›€ì„ ì˜ˆì¸¡í•˜ê³  í•´ë‹¹í•˜ëŠ” ì™¸ë¡œì›€ë“¤ì„ ì¶œë ¥í•´ì•¼í•©ë‹ˆë‹¤.\\\\\n",
    "    ì¶œë ¥ ì˜ˆì‹œ:\n",
    "    [ì™¸ë¡œì›€ ì¢…ë¥˜, ë¶„ì„ ê²°ê³¼]\n",
    "    - 000 ë‹˜ì´ í•´ë‹¹í•˜ëŠ” í•œêµ­í˜• ì™¸ë¡œì›€ì€ OOO 00%, OOO 00% ...ì…ë‹ˆë‹¤. \n",
    "    - OOO ì™¸ë¡œì›€ì€ ..., ...í•œ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì‚¬ìš©ìì˜ ê²½ìš° ...í•œ ê²½í—˜ìœ¼ë¡œ ì¸í•´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤..\\\\\n",
    "    - OOO ì™¸ë¡œì›€ì€ ..., ...í•œ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì‚¬ìš©ìì˜ ê²½ìš° ...í•œ ê²½í—˜ìœ¼ë¡œ ì¸í•´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤..\\\\\n",
    "    - ...\n",
    "    [ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì´ìœ ]\n",
    "    - ì™¸ë¡œì›€ ì¢…ë¥˜ì— ëŒ€í•œ ì„¤ëª…\n",
    "    - íŒë‹¨ ê·¼ê±°\n",
    "    \n",
    "    [ëŒ€í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]\n",
    "    - ë‹¹ì‹ ì€ 000ë‹˜ì„ ìœ„í•œ ëŒ€í™” ìƒëŒ€ê°€ ë˜ì–´ì£¼ì–´ì•¼í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì°¸ê³ ì‚¬í•­ì„ ë°˜ì˜í•´ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "    - ëŒ€í™”ì¤‘ ì‚¬ìš©ìì˜ ê¸°ì–µì€ ë°˜ë“œì‹œ ê¸°ì–µí•´ì•¼í•©ë‹ˆë‹¤.\n",
    "    - ë§íˆ¬ëŠ” ...í•˜ê³ , ...í•´ì•¼í•  ê²ƒì…ë‹ˆë‹¤. \n",
    "    - ...\n",
    "'''\n",
    "\n",
    "# ChatPromptTemplate.from_template() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ LLM (ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” 'gpt-4o' ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , temperatureëŠ” 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¶œë ¥ì˜ ì¼ê´€ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "model = ChatOpenAI(api_key=OPENAI_API_KEY,model='gpt-4o', temperature=0)\n",
    "\n",
    "# ë¬¸ì„œë“¤ì„ í˜•ì‹í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "# ê° ë¬¸ì„œì˜ í˜ì´ì§€ ë‚´ìš©ì„ í•©ì³ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG (Retrieval-Augmented Generation) ì²´ì¸ì„ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "# ì´ ì²´ì¸ì€ ë¬¸ì„œ ê²€ìƒ‰, í˜•ì‹í™”, í”„ë¡¬í”„íŠ¸ ì ìš©, ëª¨ë¸ í˜¸ì¶œ, ì¶œë ¥ íŒŒì‹±ì˜ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}  # 'context'ëŠ” retrieverì™€ format_docsë¥¼ í†µí•´ ì„¤ì •ë˜ê³ , 'question'ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
    "    | prompt  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    | model  # ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "    | StrOutputParser()  # ì¶œë ¥ íŒŒì„œë¥¼ í†µí•´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "# ì…ë ¥ ë©”ì‹œì§€ëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "input_message =  \"\"\"\n",
    "1.\\\\\n",
    "Q: ì–´ë–¤ ìƒí™©ì—ì„œ ì™¸ë¡œì›€ì„ ëŠë¼ì‹œë‚˜ìš”? \\\\\n",
    "A: ê°€ì¥ ì™¸ë¡œì› ë˜ ìƒí™©ì€ ê°€ì¡±ë“¤ê³¼ ë–¨ì–´ì ¸ ì‚´ì•˜ì„ ë•Œì…ë‹ˆë‹¤. ë‚´ê°€ ì Šì„ ë•Œ ê¸°ëŸ¬ê¸° ì•„ë¹ ì˜€ì–´ìš”. ë°¤ì— í˜¼ì ì§‘ì— ê°€ëŠ”ë° ì§‘ì— ê°€ë„ ì•„ë¬´ë„ ì—†ê² êµ¬ë‚˜ ì‹¶ì–´ì„œ í˜ë“¤ë”ë¼ê³ ìš”. ì§€ê¸ˆë„ ê°€ë” ìƒê°ë‚˜ìš”. \\\\\n",
    "2. \\\\\n",
    "Q: ì™¸ë¡­ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œë˜ì‹  ìƒí™©ì´ ì–´ë–¤ê±´ê°€ìš”? \\\\\n",
    "A: ì§‘ì— ê°€ì¡±ë“¤ì´ í•œë²ˆ ì™”ì—ˆëŠ”ë°, ê°€ì¡±ë“¤ ë‹¤ ë³´ë‚´ê³  ì§‘ì— í˜¼ììˆìœ¼ë‹ˆê¹Œ í•œìˆ¨ì´ ë‚˜ì˜¤ë”ë¼êµ¬ìš”. ì•„ ë‚´ê°€ ì™¸ë¡œìš´ê±°êµ¬ë‚˜ ì‹¶ì—ˆì–´ìš”. \\\\\n",
    "3. \\\\\n",
    "Q: ì™¸ë¡œìš¸ ë•Œ ê°€ì¥ í•„ìš”í•œê²Œ ë¬´ì—‡ì´ì—ˆë‚˜ìš”? \\\\\n",
    "A: ê°€ì¡±ì´ ì œì¼ í•„ìš”í–ˆì£ . ê·¸ëŸ°ë° ê·¸ëƒ¥ ë­”ê°€ ë‹µë‹µí•¨ì„ ë§í• ë§Œí•œ ì‚¬ëŒì´ ìˆì—ˆìœ¼ë©´ ì¢‹ì•˜ì„í…ë° ê·¸ëŸ° ì‚¬ëŒì´ ì—†ì—ˆì–´ìš”. \\\\\n",
    "\"\"\" + INPUT_PROMPT  # ì¶”ê°€ì ì¸ ì…ë ¥ í”„ë¡¬í”„íŠ¸ê°€ ì´ì–´ì§‘ë‹ˆë‹¤.\n",
    "text = rag_chain.invoke(input_message)\n",
    "# to_markdown() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì²´ì¸ì˜ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'InMemoryChatMessageHistory' has no attribute 'from_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         store[session_id] \u001b[38;5;241m=\u001b[39m ChatMessageHistory()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store[session_id]\n\u001b[0;32m---> 19\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[43mChatMessageHistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_message\u001b[49m(\n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# ChatPromptTemplate.from_template() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'InMemoryChatMessageHistory' has no attribute 'from_message'"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "model = ChatOpenAI(api_key=OPENAI_API_KEY,model='gpt-4o', temperature=0)\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "template = ChatPromptTemplate.from_message(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ {ability} ì— ëŠ¥ìˆ™í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 20ì ì´ë‚´ë¡œ ì‘ë‹µí•˜ì„¸ìš”\",\n",
    "        ),\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, history ê°€ MessageHistory ì˜ key ê°€ ë¨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # ì‚¬ìš©ì ì…ë ¥ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model\n",
    "  \n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory ê°ì²´ ìƒì„±\n",
    "        runnable,  # ì‹¤í–‰í•  Runnable ê°ì²´\n",
    "        get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "        input_messages_key=\"input\",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤\n",
    "        history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    "    )\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œë“¤ì„ í˜•ì‹í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "# ê° ë¬¸ì„œì˜ í˜ì´ì§€ ë‚´ìš©ì„ í•©ì³ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "input_message =  ''' '''\n",
    "text = rag_chain.invoke(input_message)\n",
    "# to_markdown() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì²´ì¸ì˜ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ë‹¹ì‹ ì€ ê¹€ì˜ìˆ˜ ë‹˜ì„ ìœ„í•œ ëŒ€í™” ìƒëŒ€ê°€ ë˜ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì°¸ê³ ì‚¬í•­ì„ ë°˜ì˜í•´ ì¶œë ¥í•˜ì„¸ìš”.\n",
      "- ëŒ€í™” ì¤‘ ì‚¬ìš©ìì˜ ê¸°ì–µì€ ë°˜ë“œì‹œ ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ê³µê°ì ì´ì–´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "- ê¹€ì˜ìˆ˜ ë‹˜ì´ ê°€ì¡±ë“¤ê³¼ ë–¨ì–´ì ¸ ì‚´ì•˜ë˜ ê²½í—˜, í˜„ì¬ ê±´ê°• ìƒíƒœê°€ ì¢‹ì§€ ì•Šì•„ ì§‘ì— ë¨¸ë¬´ëŠ” ì‹œê°„ì´ ë§ë‹¤ëŠ” ì , ê°€ì¡±ë“¤ê³¼ì˜ ê´€ê³„ ì†Œí™€ë¡œ ì¸í•´ ì™¸ë¡œì›€ì„ ëŠë‚€ë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ê³  ëŒ€í™”ì— ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ê¹€ì˜ìˆ˜ ë‹˜ì´ ì™¸ë¡œì›€ì„ ëŠë‚„ ë•Œ í•„ìš”í•œ ê²ƒì€ ê°€ì¡±ê³¼ì˜ ëŒ€í™”ì™€ ë‹µë‹µí•¨ì„ ë§í•  ìˆ˜ ìˆëŠ” ì‚¬ëŒì´ë¼ëŠ” ì ì„ ê¸°ì–µí•˜ê³ , ëŒ€í™” ì¤‘ì— ì´ë¥¼ ë°˜ì˜í•˜ì—¬ ê³µê°ê³¼ ìœ„ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´\n",
    "pattern = r\"\\[ëŒ€í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\\](.*)\"\n",
    "\n",
    "# íŒ¨í„´ì— ë§ëŠ” ë¬¸ìì—´ ì°¾ê¸°\n",
    "match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    result = match.group(1).strip()\n",
    "    print(result)\n",
    "    \n",
    "with open('data/prompt_output.txt', 'w') as file:\n",
    "    file.write(result)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™¸ë¡œì›€ì€ íƒ€ì¸ê³¼ì˜ ê´€ê³„ì—ì„œ ì†Œí†µì´ ë¶€ì¡±í•˜ê±°ë‚˜ í˜¼ì ê²©ë¦¬ëœ ìƒíƒœì—ì„œ ëŠë¼ëŠ” ê°ì •ì…ë‹ˆë‹¤. ì™¸ë¡œì›€ì€ ë‹¨ì§€ í˜¼ì ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì¤‘ìš”í•œ ê´€ê³„ë‚˜ ìƒí˜¸ì‘ìš©ì´ ë¶€ì¡±í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤. íŠ¹íˆ ìš°ë¦¬ë‚˜ë¼ì—ì„œëŠ” ê°ì •ì„ ì¸ì‹í•˜ê³  í‘œí˜„í•˜ëŠ” ê²ƒì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ìì‹ ì´ ì™¸ë¡œì›€ì„ ëŠë¼ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹«ê³  í‘œí˜„í•˜ëŠ” ê³¼ì •ì´ ë” í˜ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ë“œë¦¬ê³  ì‹¶ì€ë°ìš”, ìµœê·¼ì— ì–´ë–¤ ì¼ë¡œ ì™¸ë¡œì›€ì„ ëŠë¼ì…¨ë‚˜ìš”? ì €ëŠ” ì–¸ì œë‚˜ ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ì„ ì¤€ë¹„ê°€ ë˜ì–´ ìˆì–´ìš”. í˜¼ìì„œ ì†ìƒí•´í•˜ì§€ ë§ê³  ë§ˆìŒì„ ë‚˜ëˆ ì£¼ì„¸ìš”. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "class chaingpt:\n",
    "    def __init__(self,api_key, retriever, sys_prompt):\n",
    "        self.template = sys_prompt + '''Answer the question based only on the following context:\n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "        '''\n",
    "        self.prompt = ChatPromptTemplate.from_template(self.template)\n",
    "        self.model = ChatOpenAI(api_key=api_key,model='gpt-4o', temperature=1)\n",
    "        self.chainmodel = (\n",
    "        {'context': retriever | format_docs, 'question': RunnablePassthrough()}  # 'context'ëŠ” retrieverì™€ format_docsë¥¼ í†µí•´ ì„¤ì •ë˜ê³ , 'question'ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
    "        | self.prompt  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "        | self.model  # ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "        | StrOutputParser()  # ì¶œë ¥ íŒŒì„œë¥¼ í†µí•´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        )\n",
    "    def invoke(self,input_message):\n",
    "        return self.chainmodel.invoke(input_message)\n",
    "    \n",
    "#ex\n",
    "api_key = OPENAI_API_KEY\n",
    "retriever = vectordb.as_retriever()\n",
    "sys_prompt = \"\"\"ì‚¬ìš©ìì˜ ì™¸ë¡œì›€ì„ íŒë‹¨í•˜ê³ , ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ëŒ€í™” ìƒëŒ€ê°€ ë˜ì–´ì£¼ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \"\"\"\n",
    "gpt = chaingpt(api_key,retriever,sys_prompt)\n",
    "input_message =  \"\"\"ì‚¬ìš©ìì˜ ì™¸ë¡œì›€ì€ ë­”ê°€ìš”? ì ì ˆí•œ ëŒ€í™”ìƒëŒ€ê°€ ë˜ì–´ì£¼ì„¸ìš”.\"\"\"\n",
    "print(gpt.invoke(input_message))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiservice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
